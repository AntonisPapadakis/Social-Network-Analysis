{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1_0Ay-tnpzL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import networkx as nx\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from stellargraph import StellarGraph\n",
        "from stellargraph.data import BiasedRandomWalk\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.cluster import *\n",
        "from functions import draw_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21Pxr8z3n1z6"
      },
      "outputs": [],
      "source": [
        "fname = os.path.join(dir.graphs_dir, \"projected_graph_with_integer_labels.edgelist\")\n",
        "g = nx.read_weighted_edgelist(fname, nodetype=str)\n",
        "G = StellarGraph.from_networkx(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1JTxWLxtKS0"
      },
      "outputs": [],
      "source": [
        "fname = os.path.join(dir.data_dir, \"ground_truth_clusters_pickle\")\n",
        "with open(fname, 'rb') as fp:\n",
        "    clusters = pickle.load(fp)\n",
        "\n",
        "ground_truth_label = {}\n",
        "\n",
        "for i, cluster in enumerate(clusters):\n",
        "    for v in cluster:\n",
        "        ground_truth_label[v] = i\n",
        "\n",
        "ground_truth_labels = []\n",
        "for node in range(234):\n",
        "    ground_truth_labels.append(ground_truth_label[node])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6iqWHLPfdFU"
      },
      "outputs": [],
      "source": [
        "rw = BiasedRandomWalk(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIAkLHblfmIh"
      },
      "source": [
        "### Evaluation for different values of p, q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq776vU7AcBn"
      },
      "outputs": [],
      "source": [
        "p = q = [0.25, 0.5, 1, 2, 4]\n",
        "arrays = [\n",
        "    np.array([0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4]),\n",
        "    np.array([0.25, 0.5, 1, 2, 4]*5)\n",
        "]\n",
        "eval_df = pd.DataFrame(index=arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "XqCHpWgNAtS4",
        "outputId": "d77ef499-03e6-4252-95cf-437ccbb92ecd"
      },
      "outputs": [],
      "source": [
        "for u in p:\n",
        "  for v in q:\n",
        "\n",
        "    weighted_walks = rw.run(\n",
        "        nodes=G.nodes(),  # root nodes\n",
        "        length=100,  # maximum length of a random walk\n",
        "        n=30,  # number of random walks per root node\n",
        "        p=u,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "        q=v,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        "        weighted=True,  # for weighted random walks\n",
        "        seed=2\n",
        "    )\n",
        "\n",
        "    weighted_model = Word2Vec(weighted_walks, size=128, window=5, min_count=0, sg=1, workers=1, iter=1)\n",
        "\n",
        "    df = (\n",
        "        pd.DataFrame(\n",
        "            [weighted_model.wv[str(n)] for n in range(234)],\n",
        "            index = [i for i in range(234)]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    embeddings = df.values\n",
        "\n",
        "    km = KMeans(n_clusters=4)\n",
        "    km.fit(embeddings)\n",
        "    labels_pred = km.labels_\n",
        "\n",
        "    mi = mutual_info_score(labels_pred, ground_truth_labels)\n",
        "    nmi = normalized_mutual_info_score(labels_pred, ground_truth_labels)\n",
        "    ami = adjusted_mutual_info_score(labels_pred, ground_truth_labels)\n",
        "    rand = rand_score(labels_pred, ground_truth_labels)\n",
        "    hom = homogeneity_score(labels_pred, ground_truth_labels)\n",
        "    comp = completeness_score(labels_pred, ground_truth_labels)\n",
        "\n",
        "    eval_df.loc[(u, v), \"MI\"] = mi\n",
        "    eval_df.loc[(u, v), \"NMI\"] = nmi\n",
        "    eval_df.loc[(u, v), \"AMI\"] = ami\n",
        "    eval_df.loc[(u, v), \"Rand\"] = rand\n",
        "    eval_df.loc[(u, v), \"Hom\"] = hom\n",
        "    eval_df.loc[(u, v), \"Comp\"] = comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDTz4lRt6niF"
      },
      "outputs": [],
      "source": [
        "fname = os.path.join(dir.tables_dir, \"kmeans_metrics_different_p_q.csv\")\n",
        "eval_df.to_csv(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### p=q=0.25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ytdYQ6-NA4Y",
        "outputId": "60533e49-dc7c-4820-f660-a05394cbbc4c"
      },
      "outputs": [],
      "source": [
        "weighted_walks = rw.run(\n",
        "    nodes=G.nodes(),  # root nodes\n",
        "    length=100,  # maximum length of a random walk\n",
        "    n=30,  # number of random walks per root node\n",
        "    p=0.25,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "    q=0.25,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        "    weighted=True,  # for weighted random walks\n",
        "    seed=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7hhDW1i_4XU"
      },
      "source": [
        "### Evaluation for different dimesions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQPOXbKDf7Rs"
      },
      "outputs": [],
      "source": [
        "eval_df = pd.DataFrame(index=[4, 8, 16, 32, 64, 128])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Si2_ZPcU92nt",
        "outputId": "85bf5d02-fc6d-4000-907e-afc02c43a518"
      },
      "outputs": [],
      "source": [
        "for dimensions in [4, 8, 16, 32, 64, 128]:\n",
        "  weighted_model = Word2Vec(weighted_walks, size=dimensions, window=5, min_count=0, sg=1, workers=1, iter=1)\n",
        "\n",
        "  df = (\n",
        "    pd.DataFrame(\n",
        "        [weighted_model.wv[str(n)] for n in range(234)],\n",
        "        index = [i for i in range(234)]\n",
        "      )\n",
        "  )\n",
        "  embeddings = df.values\n",
        "\n",
        "  km = KMeans(n_clusters=4)\n",
        "  km.fit(embeddings)\n",
        "  labels_pred = km.labels_\n",
        "\n",
        "  mi = mutual_info_score(labels_pred, ground_truth_labels)\n",
        "  nmi = normalized_mutual_info_score(labels_pred, ground_truth_labels)\n",
        "  ami = adjusted_mutual_info_score(labels_pred, ground_truth_labels)\n",
        "  rand = rand_score(labels_pred, ground_truth_labels)\n",
        "  hom = homogeneity_score(labels_pred, ground_truth_labels)\n",
        "  comp = completeness_score(labels_pred, ground_truth_labels)\n",
        "\n",
        "  eval_df.loc[dimensions, \"MI\"] = mi\n",
        "  eval_df.loc[dimensions, \"NMI\"] = nmi\n",
        "  eval_df.loc[dimensions, \"AMI\"] = ami\n",
        "  eval_df.loc[dimensions, \"Rand\"] = rand\n",
        "  eval_df.loc[dimensions, \"Hom\"] = hom\n",
        "  eval_df.loc[dimensions, \"Comp\"] = comp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SRcSmf1_TLv"
      },
      "outputs": [],
      "source": [
        "fname = os.path.join(dir.tables_dir, \"kmeans_metrics_different_dimensions.csv\")\n",
        "eval_df.to_csv(fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtKYxHxlAJgP"
      },
      "source": [
        "### p=0.25, q=0.25, dimensions=8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CsijdWHjpVz"
      },
      "source": [
        "### Evaluation for k=4 and k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHPr6fB23FvM"
      },
      "outputs": [],
      "source": [
        "weighted_model = Word2Vec(weighted_walks, size=8, window=5, min_count=0, sg=1, workers=1, iter=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUIdbLGT3KXg"
      },
      "outputs": [],
      "source": [
        "df = (\n",
        "    pd.DataFrame(\n",
        "        [weighted_model.wv[str(n)] for n in range(234)],\n",
        "        index = [i for i in range(234)]\n",
        "    )\n",
        ")\n",
        "embeddings = df.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ukVeCWnk8H2"
      },
      "source": [
        "### k=4 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHLMbqcH3Njt"
      },
      "outputs": [],
      "source": [
        "km = KMeans(n_clusters=4)\n",
        "km.fit(embeddings)\n",
        "labels_pred_4_clusters = km.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAfSn93G3to_"
      },
      "outputs": [],
      "source": [
        "mi = mutual_info_score(labels_pred_4_clusters, ground_truth_labels)\n",
        "nmi = normalized_mutual_info_score(labels_pred_4_clusters, ground_truth_labels)\n",
        "ami = adjusted_mutual_info_score(labels_pred_4_clusters, ground_truth_labels)\n",
        "rand = rand_score(labels_pred_4_clusters, ground_truth_labels)\n",
        "hom = homogeneity_score(labels_pred_4_clusters, ground_truth_labels)\n",
        "comp = completeness_score(labels_pred_4_clusters, ground_truth_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "qVfygoF0lzM0",
        "outputId": "b994429c-20b9-4682-f039-2c56cf4f8b97"
      },
      "outputs": [],
      "source": [
        "eval_df_4_clusters = pd.DataFrame([[4, mi, nmi, ami, rand, hom, comp]], \n",
        "                columns=['Clusters', 'MI', 'NMI', 'AMI', 'Rand', 'Hom', 'Comp'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wLWYOIXuWaq"
      },
      "source": [
        "### k=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Kd8KaiuX-H"
      },
      "outputs": [],
      "source": [
        "km = KMeans(n_clusters=5)\n",
        "km.fit(embeddings)\n",
        "labels_pred_5_clusters = km.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2AXF2NEudjM"
      },
      "outputs": [],
      "source": [
        "mi = mutual_info_score(labels_pred_5_clusters, ground_truth_labels)\n",
        "nmi = normalized_mutual_info_score(labels_pred_5_clusters, ground_truth_labels)\n",
        "ami = adjusted_mutual_info_score(labels_pred_5_clusters, ground_truth_labels)\n",
        "rand = rand_score(labels_pred_5_clusters, ground_truth_labels)\n",
        "hom = homogeneity_score(labels_pred_5_clusters, ground_truth_labels)\n",
        "comp = completeness_score(labels_pred_5_clusters, ground_truth_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "qkTzh6WFul6I",
        "outputId": "99bb70e5-7910-4210-c52c-4889ad6b8778"
      },
      "outputs": [],
      "source": [
        "eval_df_5_clusters = pd.DataFrame([[5, mi, nmi, ami, rand, hom, comp]], \n",
        "                columns=['Clusters', 'MI', 'NMI', 'AMI', 'Rand', 'Hom', 'Comp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "uKHHR4SovmA7",
        "outputId": "efda20ca-59ff-4b42-f651-55220be7e95f"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([eval_df_4_clusters, eval_df_5_clusters])\n",
        "fname = os.path.join(dir.tables_dir, \"kmeans_metrics_different_k.csv\")\n",
        "df.to_csv(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zScjiOQkxwmp"
      },
      "outputs": [],
      "source": [
        "a = df.loc[df.Clusters == 4, ['MI','NMI','AMI', 'Rand', 'Hom', 'Comp']].values.flatten().tolist()\n",
        "b = df.loc[df.Clusters == 5, ['MI','NMI','AMI', 'Rand', 'Hom', 'Comp']].values.flatten().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "ZXd-6mdNfTEl",
        "outputId": "8818cdf7-6226-4235-c8c4-0fe7550b33e1"
      },
      "outputs": [],
      "source": [
        "barWidth = 0.25\n",
        "fig = plt.subplots(figsize =(12, 8))\n",
        "\n",
        "br1 = np.arange(len(a))\n",
        "br2 = [x + barWidth for x in br1]\n",
        "\n",
        "plt.bar(br1, a, color ='r', width = barWidth,\n",
        "        edgecolor ='grey', label ='k=4')\n",
        "plt.bar(br2, b, color ='g', width = barWidth,\n",
        "        edgecolor ='grey', label ='k=5')\n",
        "\n",
        "plt.xticks([r + barWidth for r in range(len(a))],\n",
        "        ['MI', 'NMI', 'AMI', 'Rand', 'Hom', 'Comp'])\n",
        "\n",
        "fname = os.path.join(dir.plots_dir, \"metrics_for_different_k.png\")\n",
        "plt.legend()\n",
        "plt.savefig(fname, bbox_inches='tight', pad_inches=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NZOa20OBLfY"
      },
      "source": [
        "### Graph Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCXT-l8BBQqN",
        "outputId": "f1264c3a-26a4-4e92-d9b1-16bd5e5637d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 9, 1: 72, 2: 131, 3: 22}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "party_length = {}\n",
        "for i in range(4):\n",
        "  count = 0\n",
        "  for val in labels_pred_4_clusters:\n",
        "      if val == i:\n",
        "          count += 1\n",
        "  party_length[i] = count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIV2R-roBTKq"
      },
      "outputs": [],
      "source": [
        "colors = {}\n",
        "\n",
        "for k, v in party_length.items():\n",
        "    if v == 9:\n",
        "        colors[k] = 'k'\n",
        "    elif v == 22:\n",
        "        colors[k] = 'g'\n",
        "    elif v == 72:\n",
        "        colors[k] = 'r'\n",
        "    else:\n",
        "        colors[k] = 'b'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "id": "TezNzCk6DSDV",
        "outputId": "bed296a0-83c1-4c2e-a86e-0c4d2202122d"
      },
      "outputs": [],
      "source": [
        "labels = {n: ground_truth_label[int(n)] for n in G.nodes()}\n",
        "color_map = [colors[labels_pred_4_clusters[int(n)]] for n in G.nodes()]\n",
        "fname = os.path.join(dir.plots_dir, \"kmeans_graph.png\")\n",
        "draw_graph(g, labels, color_map, fname)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0a5145e6c304e2a9afaf5b930a2955b950bd4b81fe94f7c42930f43f42762eb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
